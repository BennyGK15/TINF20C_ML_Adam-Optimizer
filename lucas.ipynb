{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einsatzbereich\n",
    "Fürs Training komplexer neuronaler Netze\n",
    "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c\n",
    "\n",
    "https://pub.towardsai.net/why-adam-optimizer-should-not-be-the-default-learning-algorithm-a2b8d019eaa0\n",
    "\n",
    "Der Adam Optimierer wurde entwickelt, um neurale Netzwerke zu trainieren [Bushaev, 2018](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c). Adam kann außerdem dafür verwendet werden, um Pixeländerungen an Bildern durchzuführen, ohne den Hashwert zu verändern [Struppek et al., 2022, S. 6f](https://arxiv.org/pdf/2111.06628.pdf). Dazu Adam ist einfach zu implementieren, verbraucht wenig Speicher oder Prozessorleistung und kann für große Datensätze vmit vielen Parametern verwendet werden. Die vorgegebenen \"Hypter-Parameter\" benötigen wenig Anpassung um gute Ergebnisse zu liefern [Kingma, Ba, 2015, S. 1](https://arxiv.org/abs/1412.6980) (**Quelle im Leteraturverzeichnis hinterlegen**)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
